\documentclass[letterpaper]{article}
\usepackage{fullpage}
\addtolength{\hoffset}{-.5in}
\addtolength{\textwidth}{1in}
\addtolength{\voffset}{-.5in}
\addtolength{\textheight}{1in}
\begin{document}


<<startup, echo=FALSE, message=FALSE>>=
library(knitr)
opts_chunk$set(tidy.opts=list(width.cutoff=100), options(width=80))
# DCL e152 piloting. started 4 October 2022 by Jo Etzel
# fixed movie stat input files, 10 October 2022

library(RNifti)
library(stringr)
get.FTrz <- function(in.val) {
  return(.5 * log((1 + in.val) / (1 - in.val)))
} # Fisher's r-to-z transformation.
get.FTzr <- function(in.val) {
  return((exp(2 * in.val) - 1) / (exp(2 * in.val) + 1))
} # Fisher's z-to-r transformation

source("/data/nil-external/ccp/JosetAEtzel/DMCC_files/niftiPlottingFunctions.R");
rm(list = ls())
# safety option
options(warnPartialMatchDollar = TRUE)

## ROOT directory and fixed variables
in.path <- "/data/nil-external/dcl/Events152_fMRI_NeuralMechanisms/voxelwiseAnalyses/"
sub.ids <- c(paste0("0", 1:9), 11:31, 33:37);
run.ids <- 1:4;
nframes <- c(405, 467, 404, 444);  # number of frames in each run, run.ids order
mov.ids <- c("1.2.3", "6.3.9", "3.1.3", "2.4.1");  # clip names in run.ids order; see analysisPrep.R

# ----------------------------------------------

## Feature-specific parameters can be changed here to switch between PE and visual features (e.g. pixel change mean)
# movie.features <- c("pe")
movie.features <- c("pixel_change_mean", "pixel_change_var", "luminance_mean", "luminance_var")
# first and last TR of movie stat timeseries to correlate with parcel timeseries
first <- 1
last <- 500  # this number can exceed nframes, which is ok.
# input directory of the convoluted feature timeseries
# in_feature_dir <- paste0(in.path, "matlab_resampling2/out_convo_pe/")
in_feature_dir <- paste0(in.path, "matlab_resampling2/out_convo_visual/")

onset.tbl <- read.table(paste0(in.path, "e152onsets.txt"));  # delay between first TR and movie onset, in sec
#  head(onset.tbl)
#   sub.id sub.lbl run1_1.2.3 run2_6.3.9 run3_3.1.3 run4_2.4.1
# 1 sub-01 e152003   7.900409   8.328984   7.929364   8.195244
# 2 sub-02 e152004   8.856364   8.909626   8.313563   8.564747
# feature.onsets <- c(6.16, 7.88, 5.52, 6.82) # in seconds, the delay between movie onset and PE onset.
feature.onsets <- c(0, 0, 0, 0) # in seconds, if we use visual movie.features such as pixel change, onset.tbl is enough, so 

# ----------------------------------------------

## Parcel-specific parameters
# last bit of the np2 input filenames: sub-01_run-1_np2_Sch400x7.txt
suff_sch <- "np2_Sch400x7";  
# last bit of the np2 input filenames: sub-01_run-1_np2_subcortical.txt
suff_subcortical <- "np2_subcortical";  
TR <- 1.483;   # TR in seconds

subcort.tbl <- read.csv(paste0(in.path, "subcorticalKey.csv"), stringsAsFactors=FALSE);  # subcortical_94x111x94.nii.gz parcel labels
subcortical.ids <- subcort.tbl$HCP.label
sch.ids <- 1:400;   # Schaefer2018_400x7 parcellation

# output directory for correlation between feature timeseries and parcel timeseries, depending on feature type and parcel type
out_corr_dir <- paste0(in.path, "knitr_tan/median_correlation_with_shifts/visual_xcp_corrs_", first, "_", last, "/")
# check if out_corr_dir exists
if (!file.exists(out_corr_dir)) {
  dir.create(out_corr_dir)
}

# ----------------------------------------------

## Brain plotting parameters
under.img <- readNifti(paste0(in.path, "HCP_S1200T1w_94x111x94.nii.gz")); # made in analysisPrep.R
sch.img <- readNifti(paste0(in.path, "Schaefer2018_400x7_94x111x94.nii.gz"));
sub.img <- readNifti(paste0(in.path, "subcortical_94x111x94.nii.gz"));
plot.slices <- round(seq(from=27, to=72, length.out=10));   # slices to show in the brain plots
# for median/mean metrics, the range can be small, like -.05 to .2, but for individual subjects, we'd want a bigger range, like -.1 to .5
nlims <- c(-0.1, -0.5)
plims <- c(0.1, 0.5)   # used in the brain-plotting code, too.

# ----------------------------------------------

# This function load the parcel-avg and pe correlation (created by corr.parcel.pe) and plot correlation for each subject.
just.plot.subject <- function(do.col, do.start, rid, sid) {
  # do.col <- "pe"; do.start <- 0; rid <- 1; sid <- 1
  # print(paste(do.col, " run", mov.ids[rid], "at various starts (starts in TR)"));
  temp.img <- array(0, dim(under.img))
  for (do.par in c("Schaefer2018_400x7", "subcortical")) {
    # specify parcel ids, parcel-pe correlations, and "under" img to plot (Schaefer or subcortical)
    if (do.par == "Schaefer2018_400x7") {
      p.ids <- sch.ids # 1:400
      p.img <- sch.img
      fname <- paste0(out_corr_dir, "matlabCorrs_", do.col, "_run", rid, "_dtFixed.txt")
      # print(paste("Loading", fname));
      cor.tbl <- read.table(fname)
    }
    if (do.par == "subcortical") {
      p.ids <- subcortical.ids
      p.img <- sub.img
      fname <- paste0(out_corr_dir, "matlabCorrs_", do.col, "_run", rid, "_dtFixed_subcortical.txt")
      cor.tbl <- read.table(fname)
    }
    # use column name since parcel order not fixed for subcortical
    # for (pid in 1:length(p.ids)) {
    for (pid in p.ids) {
      # vals <- cor.tbl[which(cor.tbl$start.at == paste0("corrAt", do.start)),paste0("p", pid)];
      # temp.img[which(p.img == pid)] <- median(vals);
      # sid_str <- "01";
      sid_str <- str_pad(sid, width = 2, pad = "0")
      val <- cor.tbl[which((cor.tbl$start.at == paste0("corrAt", do.start)) & (cor.tbl$sub.id == paste0("sub-", sid_str))), paste0("p", pid)]
      temp.img[which(p.img == pid)] <- val
    }
  }
  plot.volume(temp.img, under.img, neg.lims = nlims, pos.lims = plims, ttl = paste0(do.start, mov.ids[rid], do.col))
}

# ----------------------------------------------
## Define plotting and correlation functions
# This function load the parcel-avg and pe correlation (created by corr.parcel.pe) and plot median correlation across subjects.
just.plot.median <- function(do.col, do.start, rid) {   # do.col <- "pe"; do.start <- 0; rid <- 1;
    # print(paste(do.col, " run", mov.ids[rid], "at various starts (starts in TR)"));
    temp.img <- array(0, dim(under.img));
    for (do.par in c("Schaefer2018_400x7", "subcortical")) {
      if (do.par == "Schaefer2018_400x7") {
        p.ids <- sch.ids; # 1:400
        p.img <- sch.img;
  # do.start <- 0; rid <- 1; do.col <- "pixel_change_mean";
  # made above; do.start must be in the .txt
        fname <- paste0(in.path, "knitr_tan/median_correlation_with_shifts/PECorrs/matlabCorrs_", do.col, "_run", rid, "_dtFixed.txt");
        # print(paste("Loading", fname));
        cor.tbl <- read.table(fname);
      }
      if (do.par == "subcortical") {
        p.ids <- subcortical.ids
        p.img <- sub.img;
        # do.start <- 0; rid <- 1; do.col <- "pixel_change_mean";
        # made above; do.start must be in the .txt
        fname <- paste0(in.path, "knitr_tan/median_correlation_with_shifts/PECorrs/matlabCorrs_", do.col, "_run", rid, "_dtFixed_subcortical.txt")
        cor.tbl <- read.table(fname)
      }
              # use column name since parcel order not fixed for subcortical
      # for (pid in 1:length(p.ids)) {
      for (pid in p.ids) {
        vals <- cor.tbl[which(cor.tbl$start.at == paste0("corrAt", do.start)), paste0("p", pid)];
        temp.img[which(p.img == pid)] <- median(vals);
      }
    }
  plot.volume(temp.img, under.img, neg.lims=nlims, pos.lims=plims, ttl=paste0(do.start, mov.ids[rid], " ", do.col));
}

read.xcp.schaefer <- function(sid, rid) {
  fname <- paste0(in.path, "xcp/XCP_OUTPUT_", sub.ids[sid], "/sub-", sub.ids[sid], "/run-", rid, "/fcon/schaefer400x7/sub-", sub.ids[sid], "_run-", rid, "_schaefer400x7_ts.1D")
  if (file.exists(fname)) {
    xcp.tbl <- read.delim(fname, header=FALSE, sep=" ")
    # check if any column if xcp.tbl have all values equal to 0
    if (any(apply(xcp.tbl, 2, function(x) all(x==0)))) { 
      stop(paste("all 0s in xcp.tbl for at least 1 parcel for subject", sub.ids[sid], "run", rid)) 
      }
    if (nrow(xcp.tbl) != nframes[rid] || ncol(xcp.tbl) != length(sch.ids)) { 
      stop("wrong xcp.tbl")
      }
    return(xcp.tbl)
  } else { 
    msg <- paste("missing", fname)
    stop(msg)
  }
}

read.np2.schaefer <- function(sid, rid) {
  fname <- paste0(in.path, "np2/sub-", sub.ids[sid], "_run-", rid, "_", suff_sch, ".txt")
  if (file.exists(fname)) {
    np2.tbl <- read.delim(fname)
    # check if any column if np2.tbl have all values equal to 0
    if (any(apply(np2.tbl, 2, function(x) all(x==0)))) { 
      stop(paste("all 0s in xcp.tbl for at least 1 parcel for subject", sub.ids[sid], "run", rid)) 
      }
    if (nrow(np2.tbl) != nframes[rid] || ncol(np2.tbl) != length(sch.ids)) { 
      stop("wrong np2.tbl")
      }
    return(np2.tbl)
  } else { 
    msg <- paste("missing", fname)
    stop(msg)
  }
}

trim.sub.onset <- function(parcel.tbl, sid, rid) {
  sub.onset <- onset.tbl[which(onset.tbl$sub.id == paste0("sub-", sub.ids[sid])), paste0("run", rid, "_", mov.ids[rid])]; # onset in seconds
  sub.onset <- sub.onset + feature.onsets[rid];  # if not a visual feature, how much time between movie start and PE start
  TR.onset <- round(sub.onset/TR);   # onset, in TR    
  # return xcp.tbl
  return(parcel.tbl[(TR.onset:nframes[rid]), ])
}

align.then.correlate <- function(xcp.tbl, movie.vec, p.ids, from_TR, to_TR) {
  ## temporally align the movie feature vector and the parcel BOLD time series, depending on the interval of interest (from_TR -> to_TR) in the movie
  movie.vec.aligned <- movie.vec
  # movie.vec is a vector, so nrow(movie.vec) return NULL, use length instead.
  movie.vec.aligned <- movie.vec.aligned[from_TR: min(to_TR, length(movie.vec.aligned))] # trim off the movie

  # nrow is #frames, ncol is #parcels
  TRs.aligned <- (from_TR):nrow(xcp.tbl) # #frames recorded in this session (a specific subject with a specific movie)

  if (length(TRs.aligned) < length(movie.vec.aligned)) {
    movie.vec.aligned <- movie.vec.aligned[1:length(TRs.aligned)]
  }
  if (length(movie.vec.aligned) < length(TRs.aligned)) {
    TRs.aligned <- TRs.aligned[1:length(movie.vec.aligned)]
  }

  ## correlate the aligned movie feature vector and the aligned parcel BOLD time series
  corrs <- array(NA, length(p.ids))
  for (pid in 1:length(p.ids)) {
    corr <- cor(xcp.tbl[TRs.aligned, pid], movie.vec.aligned, method = "pearson")
    # check if corr is NA
    if (is.na(corr)) {
      print("corr is NA, check values below for clues")
      print(paste0("TRs.aligned=", length(TRs.aligned), " movie.vec.aligned=", length(movie.vec.aligned)))
    }
    corrs[pid] <- corr
  }
  return(corrs)
}





# This function load parcel-average timeseries for each subject, shift them and correlate it with PE timeseries.
# All correlations are saved in a single .txt file
# corr.parcel.pe <- function(do.col, do.starts, rid, from, to, sub.ids) {
#   # do.starts <- 0:1; rid <- 1; do.col <- "pe";   # which column of the movie-stat file to correlate the BOLD against, rid is movie id.
#   # from <- 1; to <- 100;   # the duration of the movie in TRs to correlate the BOLD against.
#   for (do.par in c("Schaefer2018_400x7", "subcortical")) {
#     if (do.par == "Schaefer2018_400x7") {
#       fname.out <- paste0(out_corr_dir, "matlabCorrs_", do.col, "_run", rid, "_dtFixed.txt")
#       p.ids <- sch.ids
#       suff <- suff_sch
#     }
#     if (do.par == "subcortical") {
#       fname.out <- paste0(out_corr_dir, "matlabCorrs_", do.col, "_run", rid, "_dtFixed_subcortical.txt")
#       p.ids <- subcortical.ids
#       suff <- suff_subcortical
#     }
#     ## create a list of tables to store parcel BOLD signals for all subjects
#     # fname.out <- paste0(in.path, "knitr_tan/median_correlation_with_shifts/PECorrs/matlabCorrs_", do.col, "_run", rid, "_dtFixed.txt");
#     if (!file.exists(fname.out)) { # correlate parcel timeseries of all subjects with PE and save
#       # load in the parcel-average timeseries of all subjects for each run & store so don't need to read over and over
#       nps.lst <- vector("list", length(sub.ids))
#       for (sid in 1:length(sub.ids)) { # sid <- 1;
#         # path to parcel-average timeseries of this subject, before xcp processing
#         fname <- paste0(in.path, "np2/sub-", sub.ids[sid], "_run-", rid, "_", suff, ".txt")

#         if (file.exists(fname)) {
#           np.tbl <- read.delim(fname)
#           np.tbl <- np.tbl[, -c(1, 2)] # take off first two label columns
#           if (nrow(np.tbl) != nframes[rid] | ncol(np.tbl) != length(p.ids)) {
#             print(paste(nrow(np.tbl), nframes[rid], ncol(np.tbl), length(p.ids)))
#             stop("wrong np.tbl.")
#           }
#           sub.onset <- onset.tbl[which(onset.tbl$sub.id == paste0("sub-", sub.ids[sid])), paste0("run", rid, "_", mov.ids[rid])] # onset in seconds
#           feature.onset <- feature.onsets[rid]
#           total_onset <- sub.onset + feature.onset
#           TR.onset <- round(total_onset / TR) # onset in TR, combining subject (scanning started before movie onset) and pe onset (pe starts not at movie onset but later).

#           nps.lst[[sid]] <- np.tbl[(TR.onset:nrow(np.tbl)), ] # keep frames, starting at movie + PE start
#         } else {
#           stop("missing???")
#         }
#       }
#       rm(np.tbl, fname) # cleanup

#       ## load the movie feature timeseries
#       # load convoluted PE for this movie, used for all people
#       movie.vec <- read.csv(paste0(in_feature_dir, "conv_", mov.ids[rid], "_", do.col, "_dtFix.csv"), header = FALSE)
#       movie.vec <- unlist(movie.vec[1, ], use.names = FALSE)

#       ## for each subject, correlate each parcel timeseries with the movie feature timeseries, save all correlations in a table
#       # one output file, set of starts
#       # trim 5-10 points off the front of the movie timeseries to avoid the starting big-dip????
#       out.tbl <- data.frame(array(NA, c(length(sub.ids) * length(do.starts), length(p.ids) + 2)))
#       # column names are parcel numbers
#       colnames(out.tbl) <- c("sub.id", "start.at", paste0("p", p.ids))
#       ctr <- 1 # counter = #subs * #starts
#       for (sid in 1:length(sub.ids)) { # sid <- 2;
#         # already trimmed pre-onset frames from the parcel-average timeseries
#         # sub.onset <- onset.tbl[which(onset.tbl$sub.id == paste0("sub-", sub.ids[sid])), paste0("run", rid, "_", mov.ids[rid])];

#         for (do.start in do.starts) { #  sid <- 2;  do.start <- 0;
#           movie.vec.aligned <- movie.vec # reset
#           # movie.vec is a vector, so nrow(movie.vec) return NULL, use length instead.
#           movie.vec.aligned <- movie.vec.aligned[from: min(to, length(movie.vec.aligned))] # trim off the movie

#           # each element of nps.lst is a table (np.tbl), nrow is #frames, ncol is #parcels
#           do.TRs <- (1 + do.start + from - 1):nrow(nps.lst[[sid]]) # frames in this run, starting at do.start

#           if (length(do.TRs) < length(movie.vec.aligned)) {
#             movie.vec.aligned <- movie.vec.aligned[1:length(do.TRs)]
#           } # trim end of movie so vectors match length
#           if (length(movie.vec.aligned) < length(do.TRs)) {
#             do.TRs <- do.TRs[1:length(movie.vec.aligned)]
#           }

#           out.tbl$sub.id[ctr] <- paste0("sub-", sub.ids[sid])
#           out.tbl$start.at[ctr] <- paste0("corrAt", do.start)
#           for (pid in 1:length(p.ids)) {
#             corr <- cor(nps.lst[[sid]][do.TRs, pid], movie.vec.aligned, method = "pearson")
#             # check if corr is NA
#             if (is.na(corr)) {
#               print("corr is NA, check values below for clues")
#               print(paste0("sid=", sid, " do.start=", do.start, " do.TRs=", length(do.TRs), " movie.vec.aligned=", length(movie.vec.aligned)))
#             }
#             out.tbl[ctr, pid + 2] <- corr
#           }
#           # print(paste0("corrs=", out.tbl[ctr, 1:ncol(out.tbl)]))
#           ctr <- ctr + 1
#         }
#       }
#       print(paste("Saving", fname.out))
#       write.table(out.tbl, fname.out)
#     } else {
#       print(paste("Existed, skip:", fname.out))
#     }
#   }
#   # for (do.start in do.starts) {
#   #   just.plot(do.col, do.start, rid)
#   # }
# }


@

\noindent compiled \today\  \par
\noindent DCL events152 positive controls, with matlab convolution and downsampling. \par
\noindent files under \texttt{/data/nil-external/dcl/Events152\textunderscore fMRI\textunderscore NeuralMechanisms/voxelwiseAnalyses/} \par
\vspace{0.2 cm} 
\noindent 47 people watched movies in four fMRI runs; everyone watched the same movie in each run (four different movies total; same order for everyone). Images were preprocessed with fmriprep (volumes only), then np2 detrended and normalized, and finally parcel-averaged using the Schaefer2018 400x7 parcellation (\texttt{analysisPrep.R}). The runs had the same number of volumes for everyone but the movie onsets varied a bit (7.9 to 11.4 seconds); see \texttt{e152onsets.txt} and \texttt{getOnsets.R}. \par
\vspace{0.2 cm}
\noindent The correlations here follow the same logic as \texttt{/knitr/parcelCorrelations/movieParcelCorrelations.rnw}, but with Matt's matlab code for convolving and downsampling the framewise movie measures, \texttt{/matlab\textunderscore resampling/Bezdek\textunderscore resampling.m}. Tan Nguyen created the files with PE statistic experienced by SEM model for each frame of each movie. These stats are every 0.333 seconds, much faster than the BOLD or the TR (1.483 sec). \par
\vspace{0.2 cm}
\noindent Aligning the movie and BOLD timeseries properly before correlating has been a challenge, but seems to be sorted now. The first section gives shows the median correlation for each movie statistic and run at offset 0, which should be (and is) best. A selection of the other offsets are shown on later pages, and it's clear the correlation gets worse as the offset increases.   \par




\newpage
\noindent Correlation  \par
\vspace{0.2 cm} 
<<code2legend, echo=FALSE, dev='pdf', fig.height=0.3, fig.width=7.5, fig.align="center">>=
par(oma = rep(0.2, 4), mar = rep(0, 4), mgp = rep(0, 3))

#nlims <- c(-0.2,-0.05); plims <- c(0.05, 0.2);   # used in the brain-plotting code, too.

# blank plot
plot(x = 0, y = 0, xlim = c(-10, 131), type = "n", ylab = "", xlab = "", main = "", bty = "n", xaxt = "n", yaxt = "n")
for (i in 1:length(cols.warm)) {
  rect(xleft = 66 + i, xright = 67 + i, ybottom = -0.5, ytop = 0.5, col = cols.warm[i], border = cols.warm[i])
}
for (i in 1:length(cols.cool)) {
  rect(xleft = 53 - i, xright = 54 - i, ybottom = -0.5, ytop = 0.5, col = cols.cool[i], border = cols.cool[i])
}
text(x=-8, y=0, labels=nlims[1], adj=1, cex=0.7);   # adj=1 for right-justified text; adj=0 for left-justified
text(x=53.5, y=0, labels=nlims[2], adj=0, cex=0.7);
#text(x=60, y=0, labels=0, cex=0.8);
text(x=66, y=0, labels=plims[1], adj=1, cex=0.7);
text(x=128, y=0, labels=plims[2], adj=0, cex=0.7);

@
\vspace{0.2 cm}
<<code2, dev='pdf', cache=TRUE, echo=FALSE, fig.height=1, fig.width=8, fig.align='center'>>=

#for (i in 1:4) { just.plot("pixel_change_mean", 0, i); }
# for (do.col in movie.features) {
#   for (i in 1:4) {
#     print(paste("calculate", do.col, "correlations for run", mov.ids[i], "at various starts (starts in TR)"))
#     corr.parcel.pe(do.col, 0:0, i, first, last, sub.ids)
#   }
# }

for (do.col in movie.features) {
  for (rid in 1:4) {
    ## load the movie feature timeseries
    movie.vec <- read.csv(paste0(in_feature_dir, "conv_", mov.ids[rid], "_", do.col, "_dtFix.csv"), header = FALSE)
    movie.vec <- unlist(movie.vec[1, ], use.names = FALSE)

    ## correlate with xcp parcels and save to a table
    out.tbl <- data.frame(array(NA, c(length(sub.ids), length(sch.ids) + 1)))
    colnames(out.tbl) <- c("sub.id", paste0("p", sch.ids))
    for (sid in 1:length(sub.ids)) {
      xcp.tbl <- read.xcp.schaefer(sid, rid);
      xcp.tbl <- trim.sub.onset(xcp.tbl, sid, rid);
      corrs <- align.then.correlate(xcp.tbl, movie.vec, sch.ids, from_TR=1, to_TR=500)
      out.tbl[sid, 1] <- paste0("sub-", sub.ids[sid])
      out.tbl[sid, 2:(length(sch.ids) + 1)] <- corrs
    }
    fname.out <- paste0(out_corr_dir, "xcpCorrs_", do.col, "_run", rid, ".txt")
    write.table(out.tbl, fname.out);

  }
}

@

\newpage
\noindent Correlation  \par
\vspace{0.4 cm}

<<code4legend, echo=FALSE, dev='pdf', fig.height=0.3, fig.width=7.5, fig.align="center">>=
par(oma = rep(0.2, 4), mar = rep(0, 4), mgp = rep(0, 3))

# blank plot
plot(x = 0, y = 0, xlim = c(-10, 131), type = "n", ylab = "", xlab = "", main = "", bty = "n", xaxt = "n", yaxt = "n")
for (i in 1:length(cols.warm)) {
  rect(xleft = 66 + i, xright = 67 + i, ybottom = -0.5, ytop = 0.5, col = cols.warm[i], border = cols.warm[i])
}
for (i in 1:length(cols.cool)) {
  rect(xleft = 53 - i, xright = 54 - i, ybottom = -0.5, ytop = 0.5, col = cols.cool[i], border = cols.cool[i])
}
text(x=-8, y=0, labels=nlims[1], adj=1, cex=0.7)   # adj=1 for right-justified text; adj=0 for left-justified
text(x=53.5, y=0, labels=nlims[2], adj=0, cex=0.7)
#text(x=60, y=0, labels=0, cex=0.8);
text(x=66, y=0, labels=plims[1], adj=1, cex=0.7)
text(x=128, y=0, labels=plims[2], adj=0, cex=0.7)

@

\vspace{0.2 cm}


<<code4, dev='pdf', cache=TRUE, echo=FALSE, fig.height=1, fig.width=8, fig.align='center', results='asis', eval=TRUE>>=
# https://bookdown.org/yihui/rmarkdown-cookbook/results-asis.html: By default, text output from code chunks will be written out verbatim with two leading hashes (see Section 11.12). The text is verbatim because knitr puts it in fenced code blocks (```). If you do not want the text to be in a fenced code block (or the leading hashes), you can set the chunk option results='asis'. This is useful to programmatically break pages using cat("\n\\newpage\n"). However, it will break other printing functions, either cat or print, if the string contain "LaTEX" characters such as \ or _ (e.g. pixel_change_mean). Notice, \n will break print but not cat because print also add quotes ("") and [1] in front of the string (e.g. [1] "haha"), and "\n is an incorrect syntax. If print is used, make sure there is no \n in the string.


cat("\n\nGrouping by Movie")
# grouping by movie
for (do.col in movie.features) {
  str <- paste("\n\ncalculate", do.col, "correlations with parcel timeseries")
  # replace underscores with spaces
  str <- gsub("_", " ", str)
  cat(str)
  for (i in 1:4) {
    for (sid in 1:length(sub.ids)) {
      str <- paste("\n\nsubjects", sid, "run", mov.ids[i])
      str <- gsub("_", " ", str)
      cat(str)
      just.plot.subject(do.col, 0, i, sid)
    }
    cat("\n\\newpage\n")
  }
}

# print("Grouping by Subject")
# # grouping by subject
# for (do.col in movie.features) {
#   print(paste(do.col, "stats"));
#   for (sid in 1:47) {
#     for (i in 1:4) {
#       print(paste("subject", sid, "run", mov.ids[i], do.col, "stats"), quote=FALSE);
#       just.plot.subject(do.col, 0, i, sid);
#     }
#     cat("\n\\newpage\n");
#   }
# }
@


\end{document}